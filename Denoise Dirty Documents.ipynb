{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport os\n\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import glob\nimport matplotlib.pyplot as plt\nimport cv2\nfrom keras.preprocessing import image\nfrom keras.models import Model\nfrom keras.optimizers import Adam\nfrom keras.callbacks import EarlyStopping\nfrom keras.layers import Input, Dense, Activation, BatchNormalization, Flatten, Conv2D\nfrom keras.layers import MaxPooling2D, Dropout, UpSampling2D","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from glob import glob\ntrain_images = glob('/kaggle/input/denoising-dirty-documents/train/*.png')\ntrain_labels = glob('/kaggle/input/denoising-dirty-documents/train_cleaned/*.png')\ntest_images = glob('/kaggle/input/denoising-dirty-documents/test/*.png')\nprint(\"Total number of images in the training set: \", len(train_images))\nprint(\"Total number of cleaned images found: \", len(train_labels))\nprint(\"Total number of samples in the test set: \", len(test_images))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Sample of train images and train labels"},{"metadata":{"trusted":true},"cell_type":"code","source":"samples = train_images[:3] + train_labels[:3]\n\nf, ax = plt.subplots(2,3,figsize = (20,10))\nfor i, img in enumerate(samples):\n    img = cv2.imread(img)\n    ax[i//3, i%3].imshow(img, cmap='gray')\n    ax[i//3, i%3].axis('off')\nplt.show()  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## CV2 Method"},{"metadata":{"trusted":true},"cell_type":"code","source":"img = cv2.imread(train_images[0], cv2.IMREAD_GRAYSCALE)\nplt.imshow(img,cmap = plt.cm.gray)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# applying different thresholding  \n# techniques on the input image \nthresh1 = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 30) \nplt.imshow(thresh1,cmap = plt.cm.gray) \n# plt.imshow(thresh2,cmap = plt.cm.gray) \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# applying different thresholding  \n# techniques on the input image \nthresh2 = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 25) \nplt.imshow(thresh2,cmap = plt.cm.gray) \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image\n# cvt_image = cv2.cvtColor(thresh2, cv2.COLOR_GRAY2RGB)\nim_pil = Image.fromarray(thresh2)\nim_resized = im_pil.resize((540,420))\nim_array = image.img_to_array(im_resized)\n\nim_array.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"im_resized","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"proc_imgs = []\nfor k, figs in enumerate(zip(train_images, train_labels)):\n    train_img = cv2.imread(figs[0], cv2.IMREAD_GRAYSCALE)\n    proc_img = cv2.adaptiveThreshold(train_img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 25)\n    \n    # cvt_image = cv2.cvtColor(proc_img, cv2.COLOR_GRAY2RGB)\n    im_pil = Image.fromarray(proc_img)\n    im_resized = im_pil.resize((540,420))\n    # plt.imshow(im_resized,cmap=plt.cm.gray)\n    # plt.show()\n    im_array = image.img_to_array(im_resized).astype('float32')/255\n    \n    proc_imgs.append(im_array)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## AutoEncoder"},{"metadata":{"trusted":true},"cell_type":"code","source":"def AutoEncoder():\n    input_img = Input(shape=(420,540,1), name = 'input_image')\n    \n    # Encoder Layer\n    x = Conv2D(32, (3,3), activation='relu', padding='same', name='Conv1')(input_img)\n    x = MaxPooling2D((2,2), padding='same', name='pool1')(x)\n    \n    # Decoder\n    x = Conv2D(32, (3,3), activation='relu', padding='same', name='Conv2')(x)\n    x = UpSampling2D((2,2), name='upsample3')(x)\n    x = Conv2D(1, (3,3), activation='sigmoid', padding='same', name='Conv3')(x)\n    \n    ae = Model(inputs=input_img, outputs=x)\n    ae.compile(optimizer='Adagrad', loss='binary_crossentropy')\n    return ae","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ae = AutoEncoder()\nae.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = []\nY = []\n\nfor img in train_images:\n    img = image.load_img(img, grayscale=True,target_size=(420,540))\n    img = image.img_to_array(img).astype('float32')/255\n    X.append(img)\n\nfor img in train_labels:\n    img = image.load_img(img, grayscale=True,target_size=(420,540))\n    img = image.img_to_array(img).astype('float32')/255\n    Y.append(img)\n\n\nX = np.array(X)\nY = np.array(Y)\n\nprint(\"Size of X : \", X.shape)\nprint(\"Size of Y : \", Y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n# Split the dataset into training and validation. Always set the random state!!\nX_train, X_valid, y_train, y_valid = train_test_split(X, Y, test_size=0.2, random_state=100)\nprint(\"Total number of training samples: \", X_train.shape)\nprint(\"Total number of validation samples: \", X_valid.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train your model\nae.fit(X_train, y_train, epochs=100, batch_size=8, validation_data=(X_valid, y_valid))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_test = image.load_img(test_images[10], grayscale=True, target_size=(420,540))\nsample_test = image.img_to_array(sample_test)\nsample_test_img = sample_test.astype('float32')/255.\nsample_test_img = np.expand_dims(sample_test, axis=0)\n\n# Get the predition\npredicted_label = np.squeeze(ae.predict(sample_test_img))\n\nf, ax = plt.subplots(1,2, figsize=(10,8))\nax[0].imshow(np.squeeze(sample_test), cmap='gray')\nax[1].imshow(np.squeeze(predicted_label.astype('int8')), cmap='gray')\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}